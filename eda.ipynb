{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./list-ecommerce-for-delivery-and-review-prediction.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "qF7HrC0VqohG",
        "outputId": "2bdba4fe-57f9-4118-b312-bc0921d955b4"
      },
      "outputs": [],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DUPLIKASI DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "-BHQCreUruy4",
        "outputId": "8002e33f-fea3-44eb-d845-30430e25928a"
      },
      "outputs": [],
      "source": [
        "exact_duplicate_count = df.duplicated(keep='first').sum()\n",
        "print(\"Jumlah Data yang duplikas:\", exact_duplicate_count)\n",
        "\n",
        "exact_duplicate_rows = df[df.duplicated(keep='first')]\n",
        "display(exact_duplicate_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNs5Y2dsHn_",
        "outputId": "4a96c2f5-8650-4cc8-93ce-d3e2f6743af2"
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.drop_duplicates(keep='first')\n",
        "print(\"Number of rows after removing duplicates:\", len(df_cleaned))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CEK MISSING VALUES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aos9GdbLsQkC",
        "outputId": "0daf7d35-b12d-4bc1-b226-4c8166a5d372"
      },
      "outputs": [],
      "source": [
        "print(\"Null values per column:\")\n",
        "print(df_cleaned.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pvEpFvLsVQr"
      },
      "source": [
        "# **1. ANALISASI EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pCPYFcetpTr"
      },
      "source": [
        "### **A. analisis pengaruh ketepatan waktu dengan rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fa33067",
        "outputId": "4df7b1ad-be21-4a16-c8e6-cbea8ec2c367"
      },
      "outputs": [],
      "source": [
        "bins = [-float('inf'), -24, 0, 24, 168, float('inf')]\n",
        "labels = ['Early', 'On-Time', 'Slight Delay', 'Moderate Delay', 'Significant Delay']\n",
        "df_cleaned.loc[:, 'delivery_delay_range'] = pd.cut(df_cleaned['delivery_delay_hours'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "print(\"Value counts for 'delivery_delay_range':\")\n",
        "print(df_cleaned['delivery_delay_range'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "7b4d0827",
        "outputId": "b7ebcf4e-55c6-41d0-ed15-10babb40f663"
      },
      "outputs": [],
      "source": [
        "average_review_scores_by_delay = df_cleaned.groupby('delivery_delay_range', observed=True)['review_score'].mean()\n",
        "display(average_review_scores_by_delay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "eab1f651",
        "outputId": "05b1de10-b9bd-479b-fdd4-7513f793b93c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Use a good colormap for the bars, e.g., 'viridis'\n",
        "colors = sns.color_palette(\"viridis\", n_colors=len(average_review_scores_by_delay))\n",
        "sns.barplot(\n",
        "    x=average_review_scores_by_delay.index,\n",
        "    y=average_review_scores_by_delay.values,\n",
        "    palette=colors\n",
        ")\n",
        "plt.title('Average Review Score by Delivery Delay Range')\n",
        "plt.xlabel('Delivery Delay Range')\n",
        "plt.ylabel('Average Review Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiLwDMjUt5as"
      },
      "source": [
        "### **Penyebaran data numerik dan kategorical**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a2rfZUuWt5KX",
        "outputId": "9b57c980-a3ec-4b77-cf1c-62b004d3aafa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize numerical data distribution\n",
        "numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
        "df_cleaned[numerical_cols].hist(bins=15, figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L6rTQEb_uSLt",
        "outputId": "9b9557d5-a70e-4ba3-d32a-8cb51d6d0f1c"
      },
      "outputs": [],
      "source": [
        "# Visualize categorical data distribution in a 2x2 grid\n",
        "categorical_cols = df_cleaned.select_dtypes(include=['object', 'category']).columns\n",
        "filtered_categorical_cols = [col for col in categorical_cols if df_cleaned[col].nunique() < 20]\n",
        "\n",
        "n_plots = min(4, len(filtered_categorical_cols))\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(filtered_categorical_cols[:4]):\n",
        "    sns.countplot(data=df_cleaned, y=col, order=df_cleaned[col].value_counts().index, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "    axes[i].set_xlabel('Count')\n",
        "    axes[i].set_ylabel(col)\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(n_plots, 4):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8uY8d5tuKca"
      },
      "source": [
        "### **C.Distribus data target**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5tBP-NZuu4BQ",
        "outputId": "5c4bd774-ee40-4849-ab68-5a7987829637"
      },
      "outputs": [],
      "source": [
        "# Create a 1-row, 2-column subplot for review score distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Countplot for review score distribution\n",
        "sns.countplot(\n",
        "    data=df_cleaned,\n",
        "    x='review_score',\n",
        "    order=df_cleaned['review_score'].value_counts().index,\n",
        "    palette='viridis',\n",
        "    ax=axes[0]\n",
        ")\n",
        "axes[0].set_title('Distribution of Review Scores (Countplot)')\n",
        "axes[0].set_xlabel('Review Score')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "# Boxplot for review score distribution\n",
        "sns.boxplot(\n",
        "    data=df_cleaned,\n",
        "    y='review_score',\n",
        "    palette='viridis',\n",
        "    ax=axes[1]\n",
        ")\n",
        "axes[1].set_title('Distribution of Review Scores (Boxplot)')\n",
        "axes[1].set_ylabel('Review Score')\n",
        "axes[1].set_xlabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BNEQQTSvVZe"
      },
      "source": [
        "### Distribusi Kolom Numerik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StScc7QOvdO2",
        "outputId": "14dbcd81-371e-4a58-cdf4-995fd76effdf"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    'delivery_delay_hours', 'price', 'freight_value',\n",
        "    'product_description_lenght', 'product_photos_qty',\n",
        "    'time_to_ship_hours', 'purchase_count', 'avg_review_score'\n",
        "]\n",
        "\n",
        "# Statistik deskriptif\n",
        "descriptive_stats = df[numeric_cols].describe().T\n",
        "descriptive_stats[\"mode\"] = df[numeric_cols].mode().iloc[0]\n",
        "print(descriptive_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PL2zvO1pvhNd",
        "outputId": "619a5dac-7a41-447d-e1a6-cf5c32b10087"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 20))\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    plt.subplot(4, 2, i + 1)\n",
        "    sns.histplot(df[col], kde=True, bins=30)\n",
        "    plt.title(f'Distribusi: {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 20))\n",
        "plt.suptitle('Boxplots of Numeric Columns', fontsize=18, y=1.02)\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    plt.subplot(4, 2, i + 1)\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f'Boxplot: {col}')\n",
        "    \n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYbB_s3Vv7ye"
      },
      "source": [
        "### **Visualisasi keterkaitan harga barang dan biaya ongkir dengan rating**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50b36278"
      },
      "source": [
        "**Reasoning**:\n",
        "Create scatter plots to visualize the relationship between price and review score, and freight value and review score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bc7de080",
        "outputId": "42131d8c-e3a6-4214-fa3f-240a72ee01d4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(data=df_cleaned, x='price', y='review_score', alpha=0.5)\n",
        "plt.title('Review Score vs Price')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Review Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(data=df_cleaned, x='freight_value', y='review_score', alpha=0.5)\n",
        "plt.title('Review Score vs Freight Value')\n",
        "plt.xlabel('Freight Value')\n",
        "plt.ylabel('Review Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "2aba129a",
        "outputId": "fa531110-dcf4-467d-91eb-f60051db99d0"
      },
      "outputs": [],
      "source": [
        "price_bins = [0, 50, 100, 200, 500, 1000, float('inf')]\n",
        "price_labels = ['0-50', '51-100', '101-200', '201-500', '501-1000', '>1000']\n",
        "df_cleaned['price_range'] = pd.cut(df_cleaned['price'], bins=price_bins, labels=price_labels, right=False)\n",
        "\n",
        "freight_bins = [0, 10, 20, 30, 50, float('inf')]\n",
        "freight_labels = ['0-10', '11-20', '21-30', '31-50', '>50']\n",
        "df_cleaned['freight_range'] = pd.cut(df_cleaned['freight_value'], bins=freight_bins, labels=freight_labels, right=False)\n",
        "\n",
        "average_review_scores_by_price = df_cleaned.groupby('price_range')['review_score'].mean()\n",
        "display(average_review_scores_by_price)\n",
        "\n",
        "average_review_scores_by_freight = df_cleaned.groupby('freight_range')['review_score'].mean()\n",
        "display(average_review_scores_by_freight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3dfa275e",
        "outputId": "30419dfc-1420-4485-ff0d-8dd9f5b8c1dc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x=average_review_scores_by_price.index,\n",
        "    y=average_review_scores_by_price.values,\n",
        "    palette=sns.color_palette(\"YlGnBu\", n_colors=len(average_review_scores_by_price))\n",
        ")\n",
        "plt.title('Average Review Score by Price Range')\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Average Review Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x=average_review_scores_by_freight.index,\n",
        "    y=average_review_scores_by_freight.values,\n",
        "    palette=sns.color_palette(\"YlOrRd\", n_colors=len(average_review_scores_by_freight))\n",
        ")\n",
        "plt.title('Average Review Score by Freight Value Range')\n",
        "plt.xlabel('Freight Value Range')\n",
        "plt.ylabel('Average Review Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7RtbGa1xM4p"
      },
      "source": [
        "### **Hubungan Seller grade, sekker state dan product category dengan rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "965a6d48",
        "outputId": "26a75294-1053-4d21-de65-c6dccafa1197"
      },
      "outputs": [],
      "source": [
        "average_review_scores_by_seller_grade = df_cleaned.groupby('seller_grade')['review_score'].mean().sort_values()\n",
        "# display(average_review_scores_by_seller_grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "c245b8a4",
        "outputId": "d60e613a-ac8c-48a6-8c77-dc962acf0d85"
      },
      "outputs": [],
      "source": [
        "df_cleaned['same_state'] = (df_cleaned['seller_state'] == df_cleaned['customer_state'])\n",
        "\n",
        "average_delivery_delay_by_state = df_cleaned.groupby('same_state')['delivery_delay_hours'].mean()\n",
        "average_review_score_by_state = df_cleaned.groupby('same_state')['review_score'].mean()\n",
        "\n",
        "print(\"Average Delivery Delay Hours by State Match:\")\n",
        "display(average_delivery_delay_by_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nAverage Review Score by State Match:\")\n",
        "display(average_review_score_by_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "d901c3a9",
        "outputId": "ad87bd8e-158a-49df-eefe-194234cffb92"
      },
      "outputs": [],
      "source": [
        "average_review_scores_by_category = df_cleaned.groupby('product_category_name_english')['review_score'].mean().sort_values()\n",
        "display(average_review_scores_by_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2874c2f8",
        "outputId": "553599d2-4822-4d64-d3c3-9d05e1a88f78"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x=average_review_scores_by_seller_grade.index,\n",
        "    y=average_review_scores_by_seller_grade.values,\n",
        "    palette=\"viridis\"\n",
        ")\n",
        "plt.title('Average Review Score by Seller Grade')\n",
        "plt.xlabel('Seller Grade')\n",
        "plt.ylabel('Average Review Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(\n",
        "    x=average_review_score_by_state.index,\n",
        "    y=average_review_score_by_state.values,\n",
        "    palette=\"mako\"\n",
        ")\n",
        "plt.title('Average Review Score by Seller/Customer Same State')\n",
        "plt.xlabel('Seller and Customer in Same State')\n",
        "plt.ylabel('Average Review Score')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use a visually appealing color palette for the barplots\n",
        "fig, axes = plt.subplots(2, 1, figsize=(10, 16))\n",
        "\n",
        "# Top 5 (descending order)\n",
        "top5 = average_review_scores_by_category.sort_values(ascending=False).head(5)\n",
        "sns.barplot(\n",
        "    y=top5.index,\n",
        "    x=top5.values,\n",
        "    ax=axes[0],\n",
        "    palette=\"crest\"\n",
        ")\n",
        "axes[0].set_title('Top 5 Product Categories by Average Review Score', fontsize=16, fontweight='bold')\n",
        "axes[0].set_xlabel('Average Review Score', fontsize=13)\n",
        "axes[0].set_ylabel('Product Category', fontsize=13)\n",
        "axes[0].tick_params(axis='y', labelsize=12)\n",
        "axes[0].tick_params(axis='x', labelsize=12)\n",
        "\n",
        "# Bottom 5 (ascending order)\n",
        "bottom5 = average_review_scores_by_category.sort_values(ascending=True).head(5)\n",
        "sns.barplot(\n",
        "    y=bottom5.index,\n",
        "    x=bottom5.values,\n",
        "    ax=axes[1],\n",
        "    palette=\"flare\"\n",
        ")\n",
        "axes[1].set_title('Bottom 5 Product Categories by Average Review Score', fontsize=16, fontweight='bold')\n",
        "axes[1].set_xlabel('Average Review Score', fontsize=13)\n",
        "axes[1].set_ylabel('Product Category', fontsize=13)\n",
        "axes[1].tick_params(axis='y', labelsize=12)\n",
        "axes[1].tick_params(axis='x', labelsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flJyhxYyygb5"
      },
      "source": [
        "### **Korelasi setiap feature dengan rating Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "POlFt1ZHyUuW",
        "outputId": "3fb527e0-cd84-44f1-defe-66832d75de75"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calculate correlation matrix for numeric columns\n",
        "correlation_matrix = df_cleaned.corr(numeric_only=True)\n",
        "\n",
        "# --- 1. Correlation with Review Score (Barplot) ---\n",
        "corr_to_review = correlation_matrix['review_score'].drop('review_score').sort_values(key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(\n",
        "    y=corr_to_review.index,\n",
        "    x=corr_to_review.values,\n",
        "    palette=\"vlag\"\n",
        ")\n",
        "plt.title('Feature Correlation with Review Score', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Correlation Coefficient', fontsize=13)\n",
        "plt.ylabel('Feature', fontsize=13)\n",
        "plt.axvline(0, color='gray', linestyle='--', linewidth=1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(\n",
        "    correlation_matrix,\n",
        "    mask=mask,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='Spectral',\n",
        "    linewidths=0.7,\n",
        "    cbar_kws={\"shrink\": 0.8, \"label\": \"Correlation\"},\n",
        "    square=True,\n",
        "    annot_kws={\"size\": 10}\n",
        ")\n",
        "plt.title('Correlation Matrix of Numeric Features', fontsize=18, fontweight='bold', pad=20)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
        "plt.yticks(rotation=0, fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model = df_cleaned.copy()\n",
        "\n",
        "# Target: 0 = Bad (<3), 1 = Neutral (3-4), 2 = Good (>4)\n",
        "def map_review_score(score):\n",
        "    if score < 3:\n",
        "        return 0  # Bad\n",
        "    elif 3 <= score < 4:\n",
        "        return 1  # Neutral\n",
        "    else:\n",
        "        return 2  # Good\n",
        "\n",
        "df_model['sentiment_score'] = df_model['review_score'].apply(map_review_score)\n",
        "print(df_model['sentiment_score'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target for regression\n",
        "# Target: avg_review_score (regression)\n",
        "\n",
        "# Drop columns that should not be used as features\n",
        "drop_cols = [\n",
        "    'review_score',         # original review score (if present)\n",
        "    'avg_review_score',     # target\n",
        "    'sentiment_score',      # classification target\n",
        "    'order_id', 'product_id', 'customer_id', 'seller_id', \"customer_unique_id\",# IDs\n",
        "    'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date', 'order_estimated_delivery_date'\n",
        "]\n",
        "# Only drop columns that exist\n",
        "drop_cols = [col for col in drop_cols if col in df_model.columns]\n",
        "\n",
        "X = df_model.drop(columns=drop_cols)\n",
        "y = df_model['avg_review_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "label_encoders = {}\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_features = ['seller_state', 'customer_state', 'seller_grade', 'product_category_name_english', \n",
        "                        'delivery_delay_range', 'price_range', 'freight_range', \"same_state\"]\n",
        "\n",
        "# Apply LabelEncoder to each categorical column\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X[feature] = le.fit_transform(X[feature])\n",
        "    label_encoders[feature] = le  # Store the encoder for future use\n",
        "\n",
        "# Display the transformed dataframe\n",
        "display(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tabm rtdl-num-embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TabM (Tabular Deep Learning with Parameter-Efficient Ensembling)\n",
        "\n",
        "TabM is a state-of-the-art tabular deep learning model that efficiently imitates an ensemble of MLPs through:\n",
        "\n",
        "1. **Parameter-Efficient Ensembling**: Uses weight sharing between k submodels for efficiency\n",
        "2. **Parallel Training**: All k submodels are trained simultaneously  \n",
        "3. **Feature Embeddings**: Uses PiecewiseLinearEmbeddings for better numerical feature representation\n",
        "4. **Proper Loss Function**: Each of the k predictions is trained independently (mean loss, not loss of mean)\n",
        "\n",
        "Key advantages:\n",
        "- Better performance than traditional MLPs on tabular data\n",
        "- More efficient than full ensembles due to weight sharing\n",
        "- Handles both numerical and categorical features effectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Helper function for evaluation\n",
        "def eval_regression(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R2 Score: {r2:.4f}\")\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {}\n",
        "\n",
        "# 1. Linear Regression\n",
        "print('--- Linear Regression ---')\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "results['LinearRegression'] = eval_regression(lr, X_test_scaled, y_test)\n",
        "\n",
        "# 2. Random Forest Regressor\n",
        "print('\\n--- Random Forest Regressor ---')\n",
        "rf = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "results['RandomForest'] = eval_regression(rf, X_test_scaled, y_test)\n",
        "\n",
        "# 3. XGBoost Regressor\n",
        "print('\\n--- XGBoost Regressor ---')\n",
        "if device == 'cuda':\n",
        "    xgb = XGBRegressor(n_estimators=500, tree_method='gpu_hist', predictor='gpu_predictor', random_state=42)\n",
        "else:\n",
        "    xgb = XGBRegressor(n_estimators=500, random_state=42)\n",
        "xgb.fit(X_train_scaled, y_train)\n",
        "results['XGBoost'] = eval_regression(xgb, X_test_scaled, y_test)\n",
        "\n",
        "# 4. Decision Tree Regressor\n",
        "print('\\n--- Decision Tree Regressor ---')\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train_scaled, y_train)\n",
        "results['DecisionTree'] = eval_regression(dt, X_test_scaled, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract model names and metrics\n",
        "model_names = list(results.keys())\n",
        "mae_values = [results[model]['mae'] for model in model_names]\n",
        "rmse_values = [results[model]['rmse'] for model in model_names]\n",
        "r2_values = [results[model]['r2'] for model in model_names]\n",
        "\n",
        "# Create a bar plot for MAE, RMSE, and R2\n",
        "x = range(len(model_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot MAE\n",
        "plt.bar(x, mae_values, width=width, label='MAE', color='skyblue')\n",
        "\n",
        "# Plot RMSE\n",
        "plt.bar([i + width for i in x], rmse_values, width=width, label='RMSE', color='orange')\n",
        "\n",
        "# Plot R2\n",
        "plt.bar([i + 2 * width for i in x], r2_values, width=width, label='R2', color='green')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Comparison of Model Performance')\n",
        "plt.xticks([i + width for i in x], model_names, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model based on R2 score\n",
        "best_model_name = max(results, key=lambda model: results[model]['r2'])\n",
        "print(f\"Best model based on R2 score: {best_model_name}\")\n",
        "\n",
        "# Get the best model object\n",
        "if best_model_name == 'LinearRegression':\n",
        "    best_model = lr\n",
        "elif best_model_name == 'RandomForest':\n",
        "    best_model = rf\n",
        "elif best_model_name == 'XGBoost':\n",
        "    best_model = xgb\n",
        "elif best_model_name == 'DecisionTree':\n",
        "    best_model = dt\n",
        "elif best_model_name == 'TabM':\n",
        "    best_model = tabm_model\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model name: {best_model_name}\")\n",
        "\n",
        "import joblib\n",
        "if best_model_name == 'TabM':\n",
        "    # For PyTorch models, save the state dict\n",
        "    torch.save({\n",
        "        'model_state_dict': best_model.state_dict(),\n",
        "        'model_config': {\n",
        "            'n_num_features': X_train_scaled.shape[1],\n",
        "            'd_out': 1,\n",
        "            'k': 32,\n",
        "            'n_blocks': 3,\n",
        "            'd_block': 256,\n",
        "            'dropout': 0.1\n",
        "        }\n",
        "    }, f\"best_model_{best_model_name}.pth\")\n",
        "    print(f\"Best model saved as best_model_{best_model_name}.pth\")\n",
        "else:\n",
        "    joblib.dump(best_model, f\"best_model_{best_model_name}.pkl\")\n",
        "    print(f\"Best model saved as best_model_{best_model_name}.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. TabM Regressor (Optimized for Tabular Data)\n",
        "print('\\n--- TabM Regressor ---')\n",
        "from tabm import TabM\n",
        "from rtdl_num_embeddings import PiecewiseLinearEmbeddings\n",
        "\n",
        "# Create TabM with feature embeddings for better performance\n",
        "tabm_model = TabM.make(\n",
        "    n_num_features=X_train_scaled.shape[1],\n",
        "    d_out=1,  # Regression task\n",
        "    num_embeddings=PiecewiseLinearEmbeddings(\n",
        "        n_features=X_train_scaled.shape[1],\n",
        "        n_bins=64,  # Number of bins for piecewise linear embeddings\n",
        "        d_embedding=16  # Embedding dimension\n",
        "    ),\n",
        "    k=32,  # Ensemble size\n",
        "    n_blocks=3,  # Number of blocks in the MLP backbone\n",
        "    d_block=256,  # Hidden dimension\n",
        "    dropout=0.1,  # Dropout rate\n",
        ")\n",
        "\n",
        "if device == 'cuda':\n",
        "    tabm_model = tabm_model.cuda()\n",
        "\n",
        "# Training setup for TabM\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values)\n",
        "\n",
        "if device == 'cuda':\n",
        "    X_train_tensor = X_train_tensor.cuda()\n",
        "    X_test_tensor = X_test_tensor.cuda()\n",
        "    y_train_tensor = y_train_tensor.cuda()\n",
        "    y_test_tensor = y_test_tensor.cuda()\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(tabm_model.parameters(), lr=0.002, weight_decay=0.0003)\n",
        "\n",
        "# Loss function for regression\n",
        "def tabm_loss_fn(y_pred, y_true):\n",
        "    # TabM produces k predictions. Each must be trained separately.\n",
        "    # y_pred shape: (batch_size, k, 1) for regression\n",
        "    # y_true shape: (batch_size,)\n",
        "    \n",
        "    # Flatten predictions: (batch_size, k, 1) -> (batch_size * k,)\n",
        "    y_pred_flat = y_pred.squeeze(-1).flatten()\n",
        "    \n",
        "    # Repeat targets for each ensemble member: (batch_size,) -> (batch_size * k,)\n",
        "    y_true_repeated = y_true.repeat_interleave(tabm_model.backbone.k)\n",
        "    \n",
        "    return nn.functional.mse_loss(y_pred_flat, y_true_repeated)\n",
        "\n",
        "# Training loop\n",
        "tabm_model.train()\n",
        "n_epochs = 100\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        y_pred = tabm_model(batch_x)\n",
        "        loss = tabm_loss_fn(y_pred, batch_y)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    \n",
        "    # Early stopping\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}')\n",
        "            break\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.6f}')\n",
        "\n",
        "# Evaluation\n",
        "tabm_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_tabm = tabm_model(X_test_tensor)\n",
        "    # Average the k predictions for final prediction\n",
        "    y_pred_final = y_pred_tabm.mean(dim=1).squeeze().cpu().numpy()\n",
        "    y_test_np = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "mae_tabm = mean_absolute_error(y_test_np, y_pred_final)\n",
        "rmse_tabm = mean_squared_error(y_test_np, y_pred_final, squared=False)\n",
        "r2_tabm = r2_score(y_test_np, y_pred_final)\n",
        "\n",
        "print(f\"MAE: {mae_tabm:.4f}\")\n",
        "print(f\"RMSE: {rmse_tabm:.4f}\")\n",
        "print(f\"R2 Score: {r2_tabm:.4f}\")\n",
        "\n",
        "results['TabM'] = {'mae': mae_tabm, 'rmse': rmse_tabm, 'r2': r2_tabm}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save LabelEncoders\n",
        "for feature, encoder in label_encoders.items():\n",
        "    joblib.dump(encoder, f\"label_encoder_{feature}.pkl\")\n",
        "    print(f\"LabelEncoder for {feature} saved as label_encoder_{feature}.pkl\")\n",
        "\n",
        "# Save MinMaxScaler\n",
        "joblib.dump(scaler, \"minmax_scaler.pkl\")\n",
        "print(\"MinMaxScaler saved as minmax_scaler.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
